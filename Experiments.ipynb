{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15885abc-ac41-4612-af56-6325e1bf0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "import lpips  # pip install lpips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9ab973-c6f7-4497-a13e-8aed502f6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpips_distance(loss_fn, tensor_img0, tensor_img1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tensor_img0 = tensor_img0.to(device)\n",
    "    tensor_img1 = tensor_img1.to(device)\n",
    "    loss_fn = loss_fn.to(device)\n",
    "    \n",
    "    tensor_img0 = tensor_img0.unsqueeze(0) * 2 - 1\n",
    "    tensor_img1 = tensor_img1.unsqueeze(0) * 2 - 1\n",
    "    \n",
    "    # Compute distance\n",
    "    with torch.no_grad():\n",
    "        dist01 = loss_fn.forward(tensor_img0, tensor_img1)\n",
    "    \n",
    "    return dist01.item() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68b0c3e-a17b-4bc2-9efc-11c50b5640a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(data_dir, train_size=20000, test_size=2000):\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    test_dir = os.path.join(data_dir, \"test\")\n",
    "    # Basic transform: resize/crop images and convert to tensor.\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227, 227)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()  # Produces tensors in [0, 1]\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "    # If the dataset has more images than needed, take a random subset.\n",
    "    if len(train_dataset) > train_size:\n",
    "        indices = list(range(len(train_dataset)))\n",
    "        random.shuffle(indices)\n",
    "        train_dataset = Subset(train_dataset, indices[:train_size])\n",
    "    if len(test_dataset) > test_size:\n",
    "        indices = list(range(len(test_dataset)))\n",
    "        random.shuffle(indices)\n",
    "        test_dataset = Subset(test_dataset, indices[:test_size])\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Helper Dataset to hold a list of image samples\n",
    "class CustomListDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        data_list: list of (image_tensor, label) tuples\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_list[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6cf520-c5bd-40a4-a50f-f0aa4515a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_arch=\"alexnet\", num_classes=10):\n",
    "    if model_arch.lower() == \"alexnet\":\n",
    "        #model = models.alexnet(pretrained=True)\n",
    "        model = models.alexnet(weights=None)\n",
    "        # Replace the classifier last layer.\n",
    "        model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    else:\n",
    "        #model = models.resnet50(pretrained=True)\n",
    "        model = models.resnet50(weights=None)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train_model(model, train_loader, test_loader, device, epochs=10, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "        test_model(model, test_loader, device)\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cd13c4-18d8-4274-b704-21ffefc14dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_one_image(image_tensor):\n",
    "\n",
    "    # Rearrange image dimensions: from [C, H, W] to [H, W, C] for plt.imshow().\n",
    "    image_np = image_tensor.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Display the image.\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4de61c8-591d-4ad0-a036-5be4c0412586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformations(image_tensor):\n",
    "    _, height, width = image_tensor.shape\n",
    "    transformations = {\n",
    "        \"horizontal_flip\": transforms.RandomHorizontalFlip(p=1.0),\n",
    "        \"vertical_flip\": transforms.RandomVerticalFlip(p=1.0),\n",
    "        \"rotation\": transforms.RandomRotation(degrees=random.randint(30,300)),\n",
    "        \"color_enhancement\": transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "        # Assuming the images are at least 224x224; adjust as necessary.\n",
    "        \"random_crop\": transforms.Compose([transforms.RandomCrop((random.randint(height // 2, height), random.randint(width // 2, width))), transforms.Resize((height,width))]),\n",
    "        \"blur\": transforms.GaussianBlur(kernel_size=(7, 13))\n",
    "    }\n",
    "    return transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f06e46-a3d5-4a25-9119-2785e3f2eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Clean Training (no leakage)\n",
    "def experiment1(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate):\n",
    "    print(\"[Experiment 1] Clean Training: No train/test leakage.\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = get_model(model, num_classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(model, train_loader, test_loader, device, epochs=epochs, lr=learning_rate)\n",
    "\n",
    "\n",
    "# Experiment 2: Direct Test Leakage – add every test image to train set (remove an equal number from train)\n",
    "def experiment2(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate):\n",
    "    print(\"[Experiment 2] Direct Test Leakage: Inserting test images into training set.\")\n",
    "    num_to_remove = len(test_dataset)\n",
    "\n",
    "    # Remove extra training images to free up space\n",
    "    all_indices = list(range(len(train_dataset)))\n",
    "    random.shuffle(all_indices)\n",
    "    kept_indices = all_indices[num_to_remove:]\n",
    "    new_train_examples = [train_dataset[i] for i in kept_indices]\n",
    "\n",
    "    # Append all test images into training set.\n",
    "    for sample in test_dataset:\n",
    "        new_train_examples.append(sample)\n",
    "\n",
    "    new_train_dataset = CustomListDataset(new_train_examples)\n",
    "    train_loader = DataLoader(new_train_dataset, batch_size= batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size= batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    #num_classes = len(train_dataset.dataset.classes) if isinstance(train_dataset, Subset) else len(train_dataset.classes)\n",
    "    model = get_model( model, num_classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(model, train_loader, test_loader, device, epochs=epochs, lr=learning_rate)\n",
    "\n",
    "# Experiment 2/3: Put each test image to the train set 6 times \n",
    "def experiment23(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate):\n",
    "    print(\"[Experiment 2/3] Direct Test Leakage: Inserting test images into training set 6 times.\")\n",
    "    num_to_remove = len(test_dataset)*6\n",
    "\n",
    "    # Remove extra training images to free up space\n",
    "    all_indices = list(range(len(train_dataset)))\n",
    "    random.shuffle(all_indices)\n",
    "    kept_indices = all_indices[num_to_remove:]\n",
    "    new_train_examples = [train_dataset[i] for i in kept_indices]\n",
    "\n",
    "    # Append all test images into training set.\n",
    "    for sample in test_dataset:\n",
    "        for i in range(6):\n",
    "            new_train_examples.append(sample)\n",
    "\n",
    "    new_train_dataset = CustomListDataset(new_train_examples)\n",
    "    train_loader = DataLoader(new_train_dataset, batch_size= batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size= batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    #num_classes = len(train_dataset.dataset.classes) if isinstance(train_dataset, Subset) else len(train_dataset.classes)\n",
    "    model = get_model( model, num_classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(model, train_loader, test_loader, device, epochs=epochs, lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Experiment 3: Augmented Transformation Leakage\n",
    "# For each test image, generate 6 transformed versions and add them to the training set.\n",
    "# The training set size is kept constant by removing a number of original training images.\n",
    "def experiment3(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate):\n",
    "    print(\"[Experiment 3] Augmented Transformation Leakage: Adding transformed test images.\")\n",
    "    transformed_images = []\n",
    "    # For each test image, create transformed versions\n",
    "    for img, label in tqdm(test_dataset, desc=\"Transforming Test Images\"):\n",
    "        transformations = get_transformations(img)\n",
    "        #for t_name in [\"hflip\", \"vflip\", \"random_rotation\", \"random_crop\", \"color_enhancement\",\"blur\"]:\n",
    "        #    transformed = transform_tensor_image(img,t_name)\n",
    "        for t_name, transform in transformations.items():\n",
    "            transformed = transform(img)\n",
    "            #show_one_image(transformed)\n",
    "            transformed_images.append((transformed, label))\n",
    "    \n",
    "    T = len(transformed_images)  # total new images from test\n",
    "    num_to_remove = T\n",
    "\n",
    "    all_indices = list(range(len(train_dataset)))\n",
    "    random.shuffle(all_indices)\n",
    "    kept_indices = all_indices[num_to_remove:]\n",
    "    new_train_examples = [train_dataset[i] for i in kept_indices]\n",
    "\n",
    "    # Add the transformed test images.\n",
    "    new_train_examples.extend(transformed_images)\n",
    "    new_train_dataset = CustomListDataset(new_train_examples)\n",
    "    \n",
    "    train_loader = DataLoader(new_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    #num_classes = len(train_dataset.dataset.classes) if isinstance(train_dataset, Subset) else len(train_dataset.classes)\n",
    "    model = get_model(model, num_classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(model, train_loader, test_loader, device, epochs=epochs, lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Experiment 4: LPIPS Filtering\n",
    "# Use LPIPS to evaluate similarities between test images and training images,\n",
    "# and remove for each test image the 6 most similar training images.    \n",
    "    # Display the image.\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "def experiment4(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate):\n",
    "    print(\"[Experiment 4] LPIPS Filtering: Removing similar training images based on LPIPS.\")\n",
    "    # First, generate the training set with transformed test images, as in experiment3.\n",
    "    transformed_images = []\n",
    "    for img, label in tqdm(test_dataset, desc=\"Transforming Test Images\"):\n",
    "        transformations = get_transformations(img)\n",
    "        for t_name, transform in transformations.items():\n",
    "            transformed = transform(img)\n",
    "            transformed_images.append((transformed, label))\n",
    "    \n",
    "    T = len(transformed_images)\n",
    "    num_to_remove = T\n",
    "\n",
    "    all_indices = list(range(len(train_dataset)))\n",
    "    random.shuffle(all_indices)\n",
    "    kept_indices = all_indices[num_to_remove:]\n",
    "    remv_indices = all_indices[:num_to_remove]\n",
    "    new_train_examples = [train_dataset[i] for i in kept_indices]\n",
    "    train_examples_removed = [train_dataset[i] for i in remv_indices] \n",
    "    \n",
    "    new_train_examples.extend(transformed_images)\n",
    "\n",
    "    # Initialization of LPIPS loss\n",
    "    loss_fn = lpips.LPIPS(net='alex')\n",
    "    if torch.cuda.is_available():\n",
    "        loss_fn.cuda()\n",
    "    else:\n",
    "        loss_fn.cpu()\n",
    "\n",
    "    # For each test image, compute LPIPS distance to every training sample and remove the 6 most similar.\n",
    "    print(\"Filtering training images based on LPIPS distances...\")\n",
    "    indices_to_remove = set()\n",
    "    # THIS LOOP IS EXPENSIVE\n",
    "    for test_img, _ in tqdm(test_dataset, desc=\"LPIPS Filtering\"):\n",
    "        distances = []  # list of (idx, distance)\n",
    "        for j, (train_img, _) in enumerate(new_train_examples):\n",
    "            d = lpips_distance(loss_fn, train_img, test_img)\n",
    "            distances.append((j, d))\n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        # Remove 6 most similar training images for this test image.\n",
    "        for k in range(6):\n",
    "            indices_to_remove.add(distances[k][0])\n",
    "\n",
    "    # Remove selected training images.\n",
    "    filtered_train_examples = [ex for idx, ex in enumerate(new_train_examples) if idx not in indices_to_remove]\n",
    "\n",
    "    # To keep the training set size consistent, we need to add extra samples.\n",
    "    if len(filtered_train_examples) < len(new_train_examples):\n",
    "        num_needed = len(new_train_examples) - len(filtered_train_examples)\n",
    "        if len(filtered_train_examples) > 0:\n",
    "            #additional_examples = random.sample(filtered_train_examples, num_needed)\n",
    "            additional_examples = random.sample(train_examples_removed, num_needed)\n",
    "            filtered_train_examples.extend(additional_examples)\n",
    "    \n",
    "    new_train_dataset = CustomListDataset(filtered_train_examples)\n",
    "    train_loader = DataLoader(new_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    #num_classes = len(train_dataset.dataset.classes) if isinstance(train_dataset, Subset) else len(train_dataset.classes)\n",
    "    model = get_model(model, num_classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(model, train_loader, test_loader, device, epochs=epochs, lr=learning_rate)\n",
    "\n",
    "\n",
    "# Experiment 5: Transformation Impact Analysis\n",
    "# For each transformation, add the transformed test image to training set,\n",
    "# then for each test image compute the LPIPS distance to the 3 most similar training samples.\n",
    "# The average of these distances across test images is calculated per transformation.\n",
    "def experiment5(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate):\n",
    "    print(\"[Experiment 5] Transformation Impact Analysis\")\n",
    "    transformations = get_transformations(train_dataset[0][0])\n",
    "    results = {}\n",
    "    # For each transformation check its impact separately:\n",
    "    for t_name, transform in transformations.items():\n",
    "        print(f\"\\nProcessing transformation: {t_name}\")\n",
    "        # Create a training set solely from test images transformed with t_name.\n",
    "        transformed_train = []\n",
    "        for img, label in test_dataset:\n",
    "            transformed = transform(img)\n",
    "            transformed_train.append((transformed, label))\n",
    "        \n",
    "        distances_per_test = []\n",
    "        loss_fn = lpips.LPIPS(net='alex')\n",
    "        if torch.cuda.is_available():\n",
    "            loss_fn.cuda()\n",
    "        else:\n",
    "            loss_fn.cpu()\n",
    "        \n",
    "        # For each test image, compute LPIPS to every image in the current transformed training set.\n",
    "        for test_img, _ in tqdm(test_dataset, desc=f\"LPIPS for {t_name}\"):\n",
    "            dists = []\n",
    "            for train_img, _ in transformed_train:\n",
    "                test_tensor = test_img.unsqueeze(0) * 2 - 1\n",
    "                train_tensor = train_img.unsqueeze(0) * 2 - 1\n",
    "                with torch.no_grad():\n",
    "                    d = loss_fn(test_tensor, train_tensor).item()\n",
    "                dists.append(d)\n",
    "            # Find the 3 most similar images\n",
    "            dists.sort()\n",
    "            top3 = dists[:3]\n",
    "            mean_dist = sum(top3) / 3\n",
    "            distances_per_test.append(mean_dist)\n",
    "        overall_mean = sum(distances_per_test) / len(distances_per_test)\n",
    "        results[t_name] = overall_mean\n",
    "        print(f\"Transformation: {t_name}, Mean LPIPS distance: {overall_mean:.4f}\")\n",
    "\n",
    "    print(\"\\nOverall Transformation Impact Results:\")\n",
    "    for t_name, score in results.items():\n",
    "        print(f\"{t_name}: {score:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7afe47-cb3a-4062-ba58-bbbbf21b4e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Experiment 4] LPIPS Filtering: Removing similar training images based on LPIPS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming Test Images: 100%|████████████| 2000/2000 [00:15<00:00, 129.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msimoni/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/msimoni/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/msimoni/.local/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Filtering training images based on LPIPS distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LPIPS Filtering:   0%|                                 | 0/2000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_dir = \"./cifar_images_train_test/CIFAR-10-images/\"\n",
    "    experiment = 4        # 1,2,3,4,5,\n",
    "    model = \"alexnet\"     # \"alexnet\" or \"resnet50\"\n",
    "    batch_size = 64\n",
    "    num_classes = 10\n",
    "    epochs =  20\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    train_dataset, test_dataset = get_datasets(data_dir)\n",
    "    if experiment == 1:\n",
    "        experiment1(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate)\n",
    "    elif experiment == 2:\n",
    "        experiment2(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate)\n",
    "    elif experiment == 23:\n",
    "        experiment23(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate)\n",
    "    elif experiment == 3:\n",
    "        experiment3(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate)\n",
    "    elif experiment == 4:\n",
    "        experiment4(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate)\n",
    "    elif experiment == 5:\n",
    "        experiment5(train_dataset, test_dataset, model, batch_size, num_classes, epochs, learning_rate)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
